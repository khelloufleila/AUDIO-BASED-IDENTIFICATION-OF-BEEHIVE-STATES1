{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "#tf.random.set_seed(seed_value)\n",
    "# for later versions: \n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "#session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "#sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "#K.set_session(sess)\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m pip install SoundFile\n",
    "import glob\n",
    "import sys\n",
    "from info import i, printb, printr, printp, print\n",
    "import os\n",
    "import librosa\n",
    "import pdb\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from info import i, printb, printr, printp\n",
    "import muda\n",
    "import jams\n",
    "from sklearn import svm\n",
    "import librosa\n",
    "import keras\n",
    "import scipy.io as sio\n",
    "import io\n",
    "#-----------------------------------parameters for CNN -----------------------------------#\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "#from sklearn.metrics import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential, Input, Model \n",
    "from keras.layers import Dense, Dropout, Flatten, Activation \n",
    "from keras.layers import Conv2D , MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import accuracy_score \n",
    "import pandas as pd \n",
    "#-----------------------------------parameters for TTBOX -----------------------------------#\n",
    "import timbre_descriptor as td\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import my_tools as mt\n",
    "from collections import namedtuple\n",
    "import scipy\n",
    "import scipy.signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import matplotlib\n",
    "import swipep as swp             # used for sing le-F0 estimation\n",
    "import warnings                 # used for warning removal\n",
    "import time               # used performance benchmark\n",
    "\n",
    "#from utils import get_list_samples_names, get_features_from_samples, write_Statelabels_from_beeNotBeelabels,raw_feature_fromSample, labels2binary , get_GT_labels_fromFiles, get_items2replicate, BalanceData_online, get_list_samples_name_MFCC, SVM_Classification_BeehiveSTATE , fit_and_evaluate ,deep_model, plot_confusion_matrix, get_list_samples_name_TTBOX, Dense_Net, plot_accuracy_val_accuracy, read_HiveState_fromSampleName ,train_and_evaluate_model , cross_validation_4folds, get_list_samples_name_ , constrainedsplit, save_confusion_matrix\n",
    "\n",
    "from libda import SNR, sigmerge, data_augmentation\n",
    "from decomposition import read_beeNotBee_annotations_saves_labels,  load_audioFiles_saves_segments, uniform_block_size , write_Statelabels_from_beeNotBeelabels, read_HiveState_fromSampleName , get_list_samples_names\n",
    "from classification import SVM_Classification_BeehiveSTATE,  deep_model, Dense_Net , train_and_evaluate_model\n",
    "from cross_validation import  get_list_samples_name_, cross_validation_4folds, constrainedsplit\n",
    "from feature_extraction import raw_feature_fromSample, get_features_from_samples, labels2binary, get_GT_labels_fromFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______________________________________________________________________________________________________________\n",
    "#----------------------------------- parameters to change-----------------------------------#\n",
    "block_size=1 # blocks of 1 second\n",
    "thresholds=[0, 0.5]  # minimum length for nobee intervals: 0 or 5 seconds (creates one label file per threshold value)\n",
    "path_audioFiles=\"C:\\\\Users\\PC\\python\\Stage\\To Bee or not to Bee_the annotated dataset\"+os.sep  # path to audio files\n",
    "annotations_path=\"C:\\\\Users\\PC\\python\\Stage\\To Bee or not to Bee_the annotated dataset\"+os.sep # path to .lab files\n",
    "path_save_audio_labels= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+os.sep  # path where to save audio segments and labels files.\n",
    "#----------------------------------- parameters to change-----------------------------------#\n",
    "path_workingFolder='C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+os.sep  # path where to save audio segments and labels files.\n",
    "labels2read= 'state_labels'\n",
    "feature = 'MFCCs20'\n",
    "path_working_MFCCs20= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\MFCCs20_matrix.mat'+os.sep\n",
    "path_working_TTBox= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\TTBox_matrix.mat'+os.sep\n",
    "path_working_stft= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\stft_matrix.mat'+os.sep\n",
    "path_working_cqt= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\cqt_matrix.mat'+os.sep\n",
    "\n",
    "\n",
    "path_working_MFCC20_AG= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\MFCCs20_AG_matrix.mat'+os.sep\n",
    "\n",
    "\n",
    "\n",
    "path_save_audio_MFCCs= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\MFCCs20_matrix.mat'+os.sep \n",
    "path_save_audio_ttbox= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\ttb_mat'+os.sep \n",
    "path_save_audio_stft= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\stft_matrix.mat'+os.sep \n",
    "path_save_audio_cqt= 'C:\\\\Users\\\\PC\\\\python\\\\Stage\\\\dataset_BeeNoBee_2_second'+str(block_size)+'sec'+'\\\\cqt_matrix.mat'+os.sep \n",
    "\n",
    "nbits = 16;\n",
    "MAX_VAL = pow(2,(nbits-1)) * 1.0;\n",
    "target_names=['missing_queen', 'active']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition of the data on block size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-06-03 17:28:52 RAM64.6% 0.29GB] 17295\n"
     ]
    }
   ],
   "source": [
    "sample_ids=get_list_samples_names(path_save_audio_labels) # get sample ids from audio segments folder.\n",
    "print(len(sample_ids) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the MFCCs20 \n",
    "#X=get_features_from_samples(path_workingFolder, sample_ids, 'MFCCs20', 'NO', 0)\n",
    "\n",
    "# Claculate the stft \n",
    "#X=get_features_from_samples(path_workingFolder, sample_ids, 'stft', 'NO', 0)\n",
    "\n",
    "# Claculate the cqt \n",
    "#X=get_features_from_samples(path_workingFolder, sample_ids, 'cqt', 'NO', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification SVM: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for MFCC+SVM==> index= 'b' , path_save_audio= path_save_audio_MFCCs, \n",
    "#                filename= \"confusion_matrix for MFCC + SVM \"+str(fold)\" ,  name=\"classification report for MFCC + SVM.csv \"+str(fold)\"\n",
    "# for TTBOX+SVM ==> index='ttb_vec', path_save_audio= path_save_audio_ttbox\n",
    "#            filename=\"confusion_matrix for TTBOX + SVM \"+str(fold), name=\"classification report for TTBOX + SVM.csv \"+str(fold)\n",
    "def SVM_Classification(index, path_save_audio, filename, name )\n",
    "    ruche1,Y1,labels1, sample_ids1, ruche2,Y2,labels2, sample_ids2, ruche3,Y3,labels3, sample_ids3, ruche4,Y4,labels4, sample_ids4=get_list_samples_name_(index, path_save_audio )\n",
    "    for i in range(4):\n",
    "        fold= i+1\n",
    "        print(\"Training on Fold :\", i+1)\n",
    "\n",
    "        x_train, x_test, y_train, y_test,sample_ids_train, sample_ids_test=cross_validation_4folds(i+1, ruche1,Y1, ruche2,Y2, ruche3,Y3, ruche4,Y4 , sample_ids1 , sample_ids2 , sample_ids3 , sample_ids4) \n",
    "        print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "\n",
    "        #y_train, x_train, sample_ids1_train= BalanceData_online(y_train, x_train, sample_ids_train)\n",
    "        #y_test, x_test, sample_ids1_test= BalanceData_online(y_test, x_test, sample_ids_test)\n",
    "        # Convert features and corresponding classification labels into numpy arrays\n",
    "        X_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        X_test2 = np.array(x_test)\n",
    "        y_test2 = np.array(y_test)\n",
    "        print(y_train.shape, X_train.shape, y_test2.shape, X_test2.shape)\n",
    "\n",
    "        X_test, y_test = constrainedsplit(y_train, X_test2, y_test2, 0.7)\n",
    "        x, y, z= X_train.shape\n",
    "        x1, y1, z1= X_test.shape\n",
    "        print(\"reshape the data: \")\n",
    "        X_train= X_train.reshape(x, y*z)\n",
    "        X_test= X_test.reshape(x1, y1*z1)\n",
    "        print(y_train.shape, X_train.shape, y_test.shape, X_test.shape)\n",
    "        CLF, Test_GroundT, Train_GroundT, Test_Preds, Train_Preds, Test_Preds_Proba, Train_Preds_Proba = SVM_Classification_BeehiveSTATE(X_train, y_train , X_test, y_test, kerneloption='rbf')\n",
    "\n",
    "        # Metrics\n",
    "        print(\"Accuracy: \", metrics.accuracy_score( Test_GroundT, Test_Preds))\n",
    "        # Model Precision: what percentage of positive tuples are labeled as such?\n",
    "        print(\"Precision:\",metrics.precision_score(Test_GroundT, Test_Preds))\n",
    "        # Model Recall: what percentage of positive tuples are labelled as such?\n",
    "        print(\"Recall:\",metrics.recall_score(Test_GroundT, Test_Preds))\n",
    "\n",
    "        # Compute confusion matrix\n",
    "        confusion_mat = confusion_matrix(Test_GroundT, Test_Preds )\n",
    "        save_confusion_matrix(confusion_mat,filename, target_names )\n",
    "        report=classification_report(Test_GroundT, Test_Preds , target_names=target_names, output_dict=True)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df.to_csv(name)\n",
    "\n",
    "        print(\"=============\"*12, end=\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#______________________________MFCCs+ SVM_________________________________________________________________\n",
    "# filename= \"confusion_matrix for MFCC + SVM \"+str(fold)\" ,  name=\"classification report for MFCC + SVM.csv \"\n",
    "# SVM_Classification('b', path_save_audio_MFCCs, filename, name )\n",
    "#_______________________________TTBOX+ SVM________________________________________________________________\n",
    "#filename1=\"confusion_matrix for TTBOX + SVM \"+str(fold), name1=\"classification report for TTBOX + SVM.csv \"+str(fold)\n",
    "# SVM_Classification('ttb_vec', path_save_audio_ttbox, filename1, name1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    fold=i+1\n",
    "    print(\"classification report for MFCC + SVM.csv \"+str(fold))\n",
    "    classi_report= pd.read_csv(\"classification report for MFCC + SVM.csv \"+str(fold))\n",
    "   \n",
    "    print(classi_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification CNN & DDN: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  name=\"classification report for MFCC + CNN.csv \"+str(fold), filename=\"confusion_matrix for MFCC + CNN \"+str(fold)\n",
    "#   model_filename = \"cnn_model_cpu_multifilter_fold{}.hdf5\".format(fold)\n",
    "# classification('b', path_save_audio_MFCCs, filename, name, model_filename, deep_model )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def classification(index, path_save_audio, filename, name, model_filename, model):\n",
    "\n",
    "    model_history=[]\n",
    "    val_accuracy=[]\n",
    "    ruche1,Y1,labels1, sample_ids1, ruche2,Y2,labels2, sample_ids2, ruche3,Y3,labels3, sample_ids3, ruche4,Y4,labels4, sample_ids4=get_list_samples_name_(index, path_save_audio)\n",
    "    for i in range(4):\n",
    "        fold= i+1\n",
    "        print(\"Training on Fold :\", i+1)\n",
    "\n",
    "        x_train, x_test, y_train, y_test,sample_ids_train, sample_ids_test=cross_validation_4folds(i+1, ruche1,Y1, ruche2,Y2, ruche3,Y3, ruche4,Y4 , sample_ids1 , sample_ids2 , sample_ids3 , sample_ids4) \n",
    "        print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "\n",
    "        #y_train, x_train, sample_ids1_train= BalanceData_online(y_train, x_train, sample_ids_train)\n",
    "        #y_test, x_test, sample_ids1_test= BalanceData_online(y_test, x_test, sample_ids_test)\n",
    "        # Convert features and corresponding classification labels into numpy arrays\n",
    "        X_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        X_test2 = np.array(x_test)\n",
    "        y_test2 = np.array(y_test)\n",
    "        print(y_train.shape, X_train.shape, y_test2.shape, X_test2.shape)\n",
    "\n",
    "        X_test, y_test = constrainedsplit(y_train, X_test2, y_test2, 0.7)\n",
    "        print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n",
    "        print(\"Reshape the data\")\n",
    "        x, y, z= X_train.shape\n",
    "        X_train= X_train.reshape(-1, 20, 44, 1)\n",
    "        Y_train=y_train.reshape(-1, 1)\n",
    "\n",
    "        x, y, z= X_test.shape\n",
    "        X_test= X_test.reshape(-1, 20, 44, 1)\n",
    "        Y_test=y_test.reshape(-1, 1)\n",
    "        print(\"Encode the classification labels\")  \n",
    "        X_train = np.array(X_train.tolist())\n",
    "        Y_train = np.array(Y_train.tolist())\n",
    "        X_test = np.array(X_test.tolist())\n",
    "        Y_test = np.array(Y_test.tolist())\n",
    "        # Encode the classification labels\n",
    "        le = LabelEncoder()\n",
    "        y_train = to_categorical(le.fit_transform(Y_train)) \n",
    "        y_test = to_categorical(le.fit_transform(Y_test))\n",
    "\n",
    "        size= ( 20,44, 1)\n",
    "        model=None\n",
    "        model=model(size)\n",
    "        results, val_acc, report, confusion_matrix = train_and_evaluate_model(model, X_train, y_train, X_test, y_test,  Y_test ,epochs, batch_size, model_filename )\n",
    "        model_history.append(results)\n",
    "        val_accuracy.append(val_acc)\n",
    "        df = pd.DataFrame(report).transpose()\n",
    "        df.to_csv(name)\n",
    "        save_confusion_matrix(confusion_matrix,filename, target_names )\n",
    "        print(\"=============\"*12, end=\"\\n\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### MFCCs+CNN\n",
    "#  name_cnn=\"classification report for MFCC + CNN.csv \"+str(fold), filename_cnn=\"confusion_matrix for MFCC + CNN \"+str(fold)\n",
    "#   model_filename_cnn = \"cnn_model_cpu_multifilter_fold{}.hdf5\".format(fold)\n",
    "# classification('b', path_save_audio_MFCCs, filename_cnn, name_cnn, model_filename_cnn, deep_model )\n",
    "\n",
    "### TTBOX+DDN\n",
    "#  name_dnn=\"classification report for TTBOX + DDN.csv \"+str(fold), filename_dnn=\"confusion_matrix for TTBOX+DDN \"+str(fold)\n",
    "#   model_filename = \"denseNet_model_cpu_multifilter_fold{}.hdf5\".format(fold)\n",
    "# classification('ttb_vec', path_save_audio_ttbox, filename_ddn, name_dnn, model_filename_dnn, Dense_Net  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STFT +CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "ruche1,Y1,labels1, sample_ids1, ruche2,Y2,labels2, sample_ids2, ruche3,Y3,labels3, sample_ids3, ruche4,Y4,labels4, sample_ids4=get_list_samples_name_('b', path_save_audio_stft)\n",
    "\n",
    "# save the model history in a list after fitting so we can plot later \n",
    "model_history=[]\n",
    "val_accuracy=[]\n",
    "for i in range(4):\n",
    "    fold= i+1\n",
    "    print(\"Training on Fold :\", fold)\n",
    "    x_train, x_test, y_train, y_test,sample_ids_train, sample_ids_test=cross_validation_4folds(fold, ruche1,Y1, ruche2,Y2, ruche3,Y3, ruche4,Y4 , sample_ids1 , sample_ids2 , sample_ids3 , sample_ids4) \n",
    "    print(len(x_train), len(x_test), len(y_train), len(y_test))\n",
    "    # Read a sparse matrix \n",
    "    x_train2=[]\n",
    "    x_test2=[]\n",
    "    for l in range(len(x_train)):\n",
    "        x_train2.append(x_train[l].todense())\n",
    "    for l in range(len(x_test)):\n",
    "        x_test2.append(x_test[l].todense())\n",
    "        \n",
    "    X_train= np.array(x_train2)\n",
    "    x_Test= np.array(x_test2)\n",
    "    y_train=np.array(y_train)\n",
    "    y_test= np.array(y_test)\n",
    "    X_test, y_test = constrainedsplit(y_train, x_Test, y_test, 0.7)\n",
    "    print(X_train.shape,  X_test.shape, y_train.shape, y_test.shape)\n",
    "    X_train=X_train[:,0:512, :]\n",
    "    X_test=X_test[:, 0:512, :]\n",
    "    print(X_train.shape,  X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    print(\"Reshape the data\")\n",
    "    \n",
    "    x, y, z= X_train.shape\n",
    "    X_train= X_train.reshape(-1, 512, 43, 1)\n",
    "    Y_train=y_train.reshape(-1, 1)\n",
    "\n",
    "    x, y, z= X_test.shape\n",
    "    X_test= X_test.reshape(-1,  512, 43, 1)\n",
    "    Y_test=y_test.reshape(-1, 1)\n",
    "    \n",
    "  \n",
    "    print(\"labelencoder\")\n",
    "    # Encode the classification labels\n",
    "    le = LabelEncoder()\n",
    "    y_train = to_categorical(le.fit_transform(y_train)) \n",
    "    y_test = to_categorical(le.fit_transform(y_test))\n",
    "    \n",
    "    \n",
    "    size=( 512,43, 1)\n",
    "    model_filename = \"stft_cnn_model_cpu_multifilter_fold{}.hdf5\".format(fold)\n",
    "    model=None\n",
    "    model=deep_model(size)\n",
    "    results, val_acc, report, confusion_matrix = train_and_evaluate_model(model, X_train, y_train, X_test, y_test,  Y_test ,epochs, batch_size, model_filename )\n",
    "    model_history.append(results)\n",
    "    val_accuracy.append(val_acc)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    name=\"classification report for stft + CNN.csv \"+str(fold)\n",
    "    filename=\"confusion_matrix for stft + CNN \"+str(fold)\n",
    "    df.to_csv(name)\n",
    "    save_confusion_matrix(confusion_matrix,filename )\n",
    "\n",
    "    print(\"=============\"*12, end=\"\\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
